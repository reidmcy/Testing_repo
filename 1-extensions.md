) Choose a collection of documents for this short assignment. Get full texts from them. The content could come from txt, word or pdf files on your local computer or be scraped from some website. Make sure to get rid of irrelevant information (such as ads) from the texts. Store the texts in a list. There should be at least 30 documents in the collection. A reasonable example would be all articles of a newspaper on a particular date, or all articles in a year's *American Journal of Sociology*. State why you want to study them. Also comment on what metadata you can have for each document (the author, date, etc.). If neccessary, use regular expressions wisely to separate metadata from the main body of the text (for instance, to identify the author of a document).

2) Split each document into sentences. Count the number of sentences each document has. (In English, sentences should be seperated by a period followed by a space, i.e. ". ". But the combination may not always entail a sentence break as in the case of "George W. Bush" . Try using regular expressions and experimenting a little bit to see how to get around such exceptions." )

3) Use regular expressions to find all the words that start with the letter "b" (either small or capital), and end with the letter "a" in each document. Describe how you approach this problem. Also, count the number of times such words appear in a document.

4) Build a pandas dataframe for the collection of documents. Each document should be recorded as a row entry, and the column entries should be some characteristics of each document. Include the metadata, the sentence counts, and the 'b...a' words counts that you get from 1), 2), and 3) as column entries.
