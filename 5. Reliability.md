Note: Pyanno currently only works with python 2.7. To import pyanno, also make
sure that all the required packages are installed. See the [installation
guide](http://docs.enthought.com/uchicago-pyanno/installation.html).

```python
import pyanno
import numpy as np
```

# Example Annotation Dataset

Load Rzhetsky et al (2009)'s sample dataset, which can be found
[here](https://github.com/enthought/uchicago-pyanno/tree/master/data).

```python
from pyanno.annotations import AnnotationsContainer
x = np.loadtxt("data/testdata_numerical.txt")
anno = AnnotationsContainer.from_array(x, missing_values=[-1])
```

Interrogate the AnnotationsContainer object.

```python
anno.annotations
```

```python
anno.labels
```

```python
anno.missing_values
```

# Annotation Statistics

Compute Cohen's kappa statistics, which measures the extent of agreement between
two annotators. Here, Cohen's kappa statistics for the first two annotators are
computed.

```python
from pyanno.measures import cohens_kappa, pairwise_matrix
cohens_kappa(anno.annotations[:,0], anno.annotations[:,1])
```

Get the pairwise measure matrix.

```python
m = pairwise_matrix(cohens_kappa, anno.annotations)
print (m)
```

A heatmap visualization:

```python
import matplotlib.pyplot as plt
import seaborn as sns
ax = sns.heatmap(m)
plt.show()
```

# Models

Now we use Rzhetsky et al (2009)'s models to make inference about true label
classes. Pyanno provides four available models: ModelA, ModelB, ModelBt, and
ModelBtLoopDesign. They should give similar results. To estimate the parameters
for any models, we first need to create a new model.

```python
from pyanno.models import ModelA
# create a new instance of model A, with 4 label classes
model = ModelA.create_initial_state(4)
# other model parameters are initialized from the model prior
print(model.theta)
print(model.log_likelihood(anno.annotations))
```

Pyanno allows one to use either MLE (maximum likelihood estimation) or MAP
(maximum a posteriori estimation) to estimate model parameters. The estimates
should not differ a lot. Note that the parameters here are the accuracy of each
annotator.

```python
model.map(anno.annotations)
print model.theta
print (model.log_likelihood(anno.annotations))
```

```python
model = ModelA.create_initial_state(4)
model.mle(anno.annotations)
print model.theta
print (model.log_likelihood(anno.annotations))
```

After we have model parameters estimated, we can make inference about the true
label classes. We can calculate the posterior distribution over the true label
classes.

```python
posterior = model.infer_labels(anno.annotations)
print posterior
```

sample_posterior_over_accuracy() allows drawing samples from the posterior of
the accuracy parameters. We can use such samples to draw credible intervals.

```python
samples = model.sample_posterior_over_accuracy(anno.annotations, 200, burn_in_samples=100, thin_samples=3)
print samples.mean(axis=0)
print samples.std(axis=0)
```

Let's try everything again with ModelBt

```python
from pyanno.models import ModelBt
# create a new instance of model B, with 4 label classes and 8 annotators.
model = ModelBt.create_initial_state(4, 8)
print(model.theta)
print(model.log_likelihood(anno.annotations))
```

```python
model.map(anno.annotations)
print model.theta
print (model.log_likelihood(anno.annotations))
```

```python
posterior = model.infer_labels(anno.annotations)
print posterior
```

# Generating Annotations

Pyanno also allows one to generate artificial data from a model.

```python
model = ModelBt.create_initial_state(4, 3, theta=[0.99,0.75,0.25])
#randome generate annotations with 4 label classes and 3 annotators. The accuracy of the three annotators are 0.99, 0.75, and 0.25 respectively.
model.generate_annotations(20)
```

# Visualization

Pyanno provides a [graphical user interface](http://docs.enthought.com/uchicago-
pyanno/user_guide.html) for making plots. However, it is not compatible with
ipyton notebook. Nevertheless, nothing prevents us from making plots using
matplotlib. Let's make a plot of the accuracy of each annotator inferred from
ModelA.

```python
model = ModelA.create_initial_state(4)
model.mle(anno.annotations)
samples = model.sample_posterior_over_accuracy(anno.annotations, 200, burn_in_samples=100, thin_samples=3)
y =  samples.mean(axis=0)
y_ci = samples.std(axis=0)
```

```python
plt.figure()
plt.errorbar(range(8),y, yerr = y_ci)
plt.show()
```
